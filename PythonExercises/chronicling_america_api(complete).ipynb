{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg1_EIHEETuB"
   },
   "source": [
    "# Chronicling America API\n",
    "\n",
    "[Chronicling America](https://chroniclingamerica.loc.gov/) is a collection of digitized American newspapers dating from 1777 to 1963 provided by the Library of Congress. The collection offers an application programming interface (API) which allows users to easily harvest large amounts of data.\n",
    "\n",
    "In this notebook we will search Chronicling America's API, gather the search results into a Pandas dataframe, clean the data, and save it as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "q0-jsD68ELup"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQFGCgdRHpCb"
   },
   "source": [
    "##Chronicling America URLs\n",
    "\n",
    "If I search for a term, \"abolition\" for example, on https://chroniclingamerica.loc.gov/ I will get a results url that looks like this:\n",
    "\n",
    "https://chroniclingamerica.loc.gov/search/pages/results/?state=&date1=1770&date2=1963&proxtext=abolition&x=12&y=18&dateFilterType=yearRange&rows=20&searchType=basic\n",
    "\n",
    "These search results are human actionable, but not machine actionable. Chronicling America as an API that allows me to get machine actionable results if I add `&format=json`:\n",
    "\n",
    "https://chroniclingamerica.loc.gov/search/pages/results/?state=&date1=1770&date2=1963&proxtext=abolition&x=12&y=18&dateFilterType=yearRange&rows=20&searchType=basic&format=json\n",
    "\n",
    "If we examine the url we see that there are a number of search parameters:\n",
    "- `state=`\n",
    "- `date1=1770`\n",
    "- `date2=1963`\n",
    "- `proxtext=abolition`\n",
    "\n",
    "We can edit these values to modify our search. I change the parameters to limit our search:\n",
    "\n",
    "https://chroniclingamerica.loc.gov/search/pages/results/?state=Massachusetts&date1=1770&date2=1865&proxtext=prohibition&x=20&y=8&dateFilterType=yearRange&rows=20&searchType=basic&format=json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8x69VEy1KCpP"
   },
   "source": [
    "Now I can use the `requests` library to retrieve data from the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uoseSCpoEghd"
   },
   "outputs": [],
   "source": [
    "# initial search\n",
    "url = 'https://chroniclingamerica.loc.gov/search/pages/results/?state=&date1=1770&date2=1963&proxtext=Chumash&x=7&y=12&dateFilterType=yearRange&rows=20&searchType=basic&format=json'\n",
    "response = requests.get(url)\n",
    "raw = response.text\n",
    "results = json.loads(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-IV4qxIKlXW"
   },
   "source": [
    "## Explore search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Pg-9a2pIKTnO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['totalItems', 'endIndex', 'startIndex', 'itemsPerPage', 'items'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jB1fHVUTEcLl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# explore items\n",
    "print(type(results['items']))\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LduCA0d1Etzn",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 6, 'county': ['Hennepin', 'Ramsey'], 'edition': None, 'frequency': 'Weekly', 'id': '/lccn/sn78004468/1918-04-12/ed-1/seq-6/', 'subject': ['Hennepin County (Minn.)--Newspapers.', 'Jewish newspapers--Minnesota.', 'Jewish newspapers--United States.', 'Jewish newspapers.--fast--(OCoLC)fst00982872', 'Minneapolis (Minn.)--Newspapers.', 'Minnesota--Hennepin County.--fast--(OCoLC)fst01213354', 'Minnesota--Minneapolis.--fast--(OCoLC)fst01204260', 'Minnesota--Ramsey County.--fast--(OCoLC)fst01213443', 'Minnesota--Saint Paul.--fast--(OCoLC)fst01212130', 'Minnesota.--fast--(OCoLC)fst01204560', 'Ramsey County (Minn.)--Newspapers.', 'Saint Paul (Minn.)--Newspapers.', 'United States.--fast--(OCoLC)fst01204155'], 'city': ['Minneapolis', 'Saint Paul'], 'date': '19180412', 'title': 'The American Jewish world. [volume]', 'end_year': 9999, 'note': ['Archived issues are available in digital format from the Library of Congress Chronicling America online collection.', 'Available on microfilm from the New York Public Library and the Minnesota Historical Society.', 'Latest issue consulted: (June 16, 1978).'], 'state': ['Minnesota', 'Minnesota'], 'section_label': '', 'type': 'page', 'place_of_publication': 'Minneapolis ;', 'start_year': 1915, 'edition_label': '', 'publisher': 'Jewish World Pub. Co.', 'language': ['English'], 'alt_title': [], 'lccn': 'sn78004468', 'country': 'Minnesota', 'ocr_eng': '542\\nALL JEWS ARE BROTHERS.\\nThere is something within the per\\nson born of Jewish parents that makes\\nhim call another Jew brother, rather\\nthan his Irish, Italian, or English\\nneighbor. It is this brotherly tie be\\ntween all Jews that has justified us in\\ncalling ourselves the Jewish nation\\neven though we did not have a na\\ntional home.\\nNow, the situation is changed. The\\ngreat nations, the United States, Great\\nBritain, France, and Russia have told\\nus that if they win this war, Palestine\\nwill belong to us. Since we believe\\nso firmly that they will,win it, we may\\nalread/ call Palestine oiVrs. Many Jews\\nwill, therefore, go to Palestine and build\\nthere a Jewish Republic.\\nA great many more Jews will not\\nleave the countries where they now\\nare. Each American Jew will then have\\ntwo kinds of brothers and sisters, those\\nin Palestine and those like him in\\nAmerica. However, the love of both\\nof these brothers and sisters must not\\nbe weakened. We must love our Ameri\\ncan brothers and sisters just as much\\nas those in Palestine. It is not alto\\ngether necessary to live in Palestine to\\nbe a Jew, for the teachings of Juda\\nism can be practiced in every part of\\nthe world. Jews, wherever they will\\nbe, will ever be brothers.\\nABOUT OUR CONTEST.\\nThe Junior Editor has received many\\nletters from girls, but only from one\\nboy. Perhaps it has not been made\\nclear that the department belongs just\\nas much to boys as to girls. A family\\nis not complete without brothers, you\\nknow. If it is necessary, the Junior\\nEditor extends an invitation to all boys\\nbetween the ages of 9 and 16 to become\\npart of our family of Junior readers.\\nOf those who have sent in their an\\nswers to the puzzle of Mar. 29, nearly\\nall were correct, but not all lived up\\n\\\\to the requirements of Writing full\\nname, age, and address. Txie nexc time\\nyou write don\\'t forget these three\\nthings.\\nThe following were correct in every\\nWay but we can only give one prize.\\nSo this is the way we found the lucky\\none. All correct answers were placed\\nin -a box and the Junior Editor drew\\none out. The first one drawn was the\\nprize winner. We hope she will let us\\nknow how she liked the prize.\\nPrize winner—Ethel Gallander, Minne\\napolis.\\nEligible for prize: Nettie Barzon,\\nMiriam Deinard, Evelyn German, Ethel\\nGallander, Zetta Goldberg, Rose Wasser\\nman, Max London, all of Minneapolis\\nEthel Merman and Sophie Mildred Si\\nmon of St. Paul Helen Rosenbloom,\\nFrazee, Minn. Lillit Katz, Osceola, Wis.\\nBy April 15th your paper telling the\\nstory of the picture in the April 5th\\nnumber must be in. The prize win\\nner will be named in the next issue.\\nOf course the prize will go to the best\\nstory.\\nOUR JUNIOR DEPARTMENT\\nConducted by Ethel Katz\\nTHE AMERICAN JEWISH WORLD\\nAs you see, there will be a chance\\nfor at least one Junior reader to win\\na prize each week. There is no rea\\nson why each one of you cannot get\\none. Just try and tell your playmate\\nabout it. See which of you can win\\nthe most prizes during the year.\\nNow, the next thing that you must\\ndo to get a prize is to write a paper\\nof about two hundred words, telling\\nwhat Bible story you like best, and why\\nyou like it or what biblical character\\n\\'you like best and why. This time the\\nprize will be awarded to the best writ\\nten and most interesting letter. Your\\npaper must be in by the 22nd of April.\\nA NEW MOTHER.\\nBy Scholom Asch.\\nDavid\\'s mother had been dead just a\\nyear, and his father had married again.\\nThis was the first Sabbath since the\\nlittle boy\\'s new mother had come to\\nlive in his house. He felt strangely\\nlonely when he returned from Schul with\\nhis father, and entering the house, greet\\ned everybody with his customary \"Good\\nSabbath.\"\\nThe table was covered with a white\\ntable-cloth at one end were two twists\\nof bread and the wine the dishes were\\nclean and shining everything seemed\\norderly and well kept. Everything in\\nthe home was just as it had been when\\nhis own mother had prepared the wel\\ncome for the Sabbath bride yet David\\nfelt that he had entered a strange house.\\nHis step-mother entered from the next\\nroom as David looked at her, his heart\\nbegan to beat faster, for on her head\\nhe saw the beautiful kerchief his mother\\nhad worn. He noticed, too, that his\\nmother\\'s ear-rings hung in her ears,\\nwhile on her neck shone a golden neck\\nlace that had once been his mother\\'s.\\nDavid sat down to the table and, as\\nhe did so, he seemed to see a picture of\\nthe Sabbath meal in the days before his\\nmother had left him. He could see his\\nown deai^mother wit!| Lhe beVcuyful Sab\\nbath kerchief upon her head, the pretty\\near-rings sparkling in her ears, and the\\nnecklace shining upon her neck. She sat\\nbeside his father at the table with the\\nplates before her, and gave each his por\\ntion of fish. He and his sisters sat in\\ntheir old places around the table his\\nfather began singing Zemiroth (Sabbath\\nsongs) in which David\\'s sweet, clear voice\\njoined. Then his father took the Bible\\nand asked him questions about the first\\nchapter of the portion for the week. Da\\nvid answered all of them without\\nmaking a single mistake and, as\\nhis mother stood beside them and\\nlistened to her son\\'s words, her face\\nshone with joy and her eyes seemed to\\nshed light from sheer happiness. After\\nwards she embraced and kissed him and\\ngave him a fine apple taken from the\\ndish of Sabbath fruit\\nNow David attended Cheder, and stu\\ndied the Chumash and was able to read,\\nnot only the first chapter, but the whole\\nportion of the week. He studied \"Rashi\"\\ntoo, and he knew them both, the Chu\\nmash and \"Rashi\\'s\" comments upon it.\\nHe would have been happy if only his\\nApril 12, 1918.\\nmother could have stood beside him to\\nsee how much he had learned. He wish\\ned that she could listen to his lessons,\\nthat he could see her face beam with\\njoy and pride. But where was she now?\\n\"David, why don\\'t you help me sing?\"\\nasked his father.\\nDavid began to sing \"Menucha V\\'sim\\ncha\" (Rest and Joy), but his voice was\\nanything but joyful, and a note of sad\\nness mingled with the sound. His mother\\nno longer sat beside him to watch him\\nfondly as he chanted the beautiful Sab\\nbath melodies. Where was she now?....\\nDavid could not know. His eyes could\\nnot see clearly enough—yet he dreamed.\\nThere in the Garden of Eden among\\nthe Mothers of the nation, Sarah, Re\\nbecca, Rachel, and Leah, stands his own\\nmother. Whenever her son recites from\\nthe holy Torah, his voice is heard there,\\neve?ij in the Garden of Eden.\\nAiHl David felt thiit his good mother,\\nwho sits amongst the Mothers of Israel,\\nhears his replies when his father ex\\namines him in the Chumash, and that\\nwhen he answers his father\\'s questions\\nhere, his mother rejoices th^re. She\\nstands and listens and her eyes sparkle\\nwith joy\\n\"Papa, will you examine me today?\"\\nasked David.\\n\"Yes, my son. Bring me the Chumash.\"\\nDavid quickly rose from the table,\\nbrought the volume to his father, opened\\nit, and looked for the portion of the\\nweek......\\n\"And Jacob sojourned in the land of\\nEgypt.\"\\nDavid continued to read, just as he had\\ndone on Sabbath afternoons when his\\nmother had smiled to hear him recite.\\nCan it be that even now his loving mother\\nhears him and rejoices\\nYes, there in the Garden of Eden his\\nmother, his own mother, stands among\\nthe Mothers of Israel and listens to her\\nchild\\'s voice. \"Happy mother!\" they ex\\nclaim. \"You are indeed fortunate to be\\nworthy of a son like yours, who studies\\nand knows the holy Torah.\" She stands\\nthere, her eyes sparkling with tears of\\njoy. Then our mother Rachel approaches\\nher and reminds her that it is the Sab\\nbath day on which we are forbidden to\\nweep, and she wipes the tears from her\\neges.\\nAnd as David\\'s sweet young voice rises\\nclearer and\\' stronger, his mother stretch\\nes out her hand to the golden table, to\\ntake an apple from the Tree of Life, and\\ntries to give it to her good son for his\\n\"Sabbath fruit\"—but she cannot reach\\nhim.\\n(Adapted from the Hebrew by Louis\\nPrasher.)\\nTHE THRIFT STAMP CONTEST.\\nPupils Amt.\\nTemple Sunday School... .137 $1600.41\\nAdath Yeshurun 51 270.27\\nTalmud Torah 255 888.59\\nKennesseth Israel ........ 21 80.00\\nAT THE SHUBERT.\\nThe Players in the charming comedy\\ndrama, \"The Cinderella Man.\"\\nMISPLACED ZEAL.\\nTeacher—\"Why are you late for school?\"\\nPupil—\"Why, teacher, I must have\\noverwashed myself.\"', 'batch': 'mnhi_gavotte_ver01', 'title_normal': 'american jewish world.', 'url': 'https://chroniclingamerica.loc.gov/lccn/sn78004468/1918-04-12/ed-1/seq-6.json', 'place': ['Minnesota--Hennepin--Minneapolis', 'Minnesota--Ramsey--Saint Paul'], 'page': ''}\n"
     ]
    }
   ],
   "source": [
    "print(results['items'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "kIcPNqHuKtJA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalItems: 28\n",
      "endIndex: 20\n",
      "startIndex: 1\n",
      "itemsPerPage: 20\n",
      "Length and type of items: 20 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print('totalItems:', results['totalItems'])\n",
    "print('endIndex:', results['endIndex'])\n",
    "print('startIndex:', results['startIndex'])\n",
    "print('itemsPerPage:', results['itemsPerPage'])\n",
    "print('Length and type of items:', len(results['items']), type(results['items']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxWJPQfUK5pA"
   },
   "source": [
    "The Chronicling America API returned 1,656 results. However, it will only display 20 at a time by default. I can add a new parameter `page=` to cycle through all the results, but first I need to know how many pages there will be. I can find this out by dividing `totalItems` (1,656) by `itemsPerPage` (20) and then round-up using `math.ceil`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "OmJIDL1lKy0g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# find total amount of pages\n",
    "total_pages = math.ceil(results['totalItems'] / results['itemsPerPage'])\n",
    "print(total_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Gca6IQYUEVx"
   },
   "source": [
    "Now that I know how many pages there will be, I can use a for loop to iterate through each result page and then each item on each result page. I then gather the data I want from each item: newspaper title, city, date, and text.\n",
    "\n",
    "Notice in the code below I placed the url string in parentheses () so that I could break it up over multiple lines making it easier to read.\n",
    "\n",
    "Also, for the sake of this demonstration, I am only iterating over 10 pages. For the full results the for loop should begin: `for i in range(1, total_pages+1)` (the `+1` is necessary becase the seond number in the range function is exclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "C0pZe96qBP_J"
   },
   "outputs": [],
   "source": [
    "# create empty list for data\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "pg63qYBuBVU3"
   },
   "outputs": [],
   "source": [
    "# set search parameters\n",
    "start_date = '1770'\n",
    "end_date = '1963'\n",
    "search_term = 'Chumash'\n",
    "state = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Upp6d0I9UDy6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 1 status code: 200\n",
      "page 2 status code: 200\n"
     ]
    }
   ],
   "source": [
    "# loop through search results and collect data\n",
    "for i in range(1, total_pages+1):  # for sake of time I'm doing only 10, you will want to put total_pages+1\n",
    "    url = (f'https://chroniclingamerica.loc.gov/search/pages/results/?state={state}&date1={start_date}'\n",
    "           f'&date2={end_date}&proxtext={search_term}&x=16&y=8&dateFilterType=yearRange&rows=20'\n",
    "           f'&searchType=basic&format=json&page={i}')  # f-string\n",
    "    response = requests.get(url)\n",
    "    raw = response.text\n",
    "    print(f'page {i} status code:', response.status_code)  # checking for errors\n",
    "    results = json.loads(raw)\n",
    "    items_ = results['items']\n",
    "    for item_ in items_:\n",
    "        row_data = {}\n",
    "        try:\n",
    "          row_data['title'] = item_['title_normal']\n",
    "        except:\n",
    "          row_data['title'] = \"none\"\n",
    "        try:\n",
    "          row_data['city'] = item_['city']\n",
    "        except:\n",
    "          row_data['city'] = \"none\"\n",
    "        try:\n",
    "          row_data['date'] = item_['date']\n",
    "        except:\n",
    "          row_data['date'] = \"none\"\n",
    "        try:\n",
    "          row_data['raw_text'] = item_['ocr_eng']\n",
    "        except:\n",
    "          row_data['raw_text'] = 'none'\n",
    "    data.append(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "q-ctFdtSBa-u"
   },
   "outputs": [],
   "source": [
    "# put data into DataFrame\n",
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "prL29Su_msjb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>city</th>\n",
       "      <th>date</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>southern jewish weekly.</td>\n",
       "      <td>[Jacksonville]</td>\n",
       "      <td>19560113</td>\n",
       "      <td>-s*\\nFriday, January 13, 1956\\ns\\nThe south Fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>evening star.</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>19280630</td>\n",
       "      <td>' WILLIAM F. BRODT,!\\nHATMAKER, IS DEAD\\n, Fou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title            city      date  \\\n",
       "0  southern jewish weekly.  [Jacksonville]  19560113   \n",
       "1            evening star.    [Washington]  19280630   \n",
       "\n",
       "                                            raw_text  \n",
       "0  -s*\\nFriday, January 13, 1956\\ns\\nThe south Fl...  \n",
       "1  ' WILLIAM F. BRODT,!\\nHATMAKER, IS DEAD\\n, Fou...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z509dIQEep7G"
   },
   "source": [
    "### Change date format\n",
    "Pandas allows us to clean and edit our data easily (relatively). We can first convert the string values in the date column to properly formated dates and then sort the dataframe by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "z1fENcFaZJIx"
   },
   "outputs": [],
   "source": [
    "# convert date column from string to date-time object\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "4c0otcZIey1D"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>city</th>\n",
       "      <th>date</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>southern jewish weekly.</td>\n",
       "      <td>[Jacksonville]</td>\n",
       "      <td>1956-01-13</td>\n",
       "      <td>-s*\\nFriday, January 13, 1956\\ns\\nThe south Fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>evening star.</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>1928-06-30</td>\n",
       "      <td>' WILLIAM F. BRODT,!\\nHATMAKER, IS DEAD\\n, Fou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title            city       date  \\\n",
       "0  southern jewish weekly.  [Jacksonville] 1956-01-13   \n",
       "1            evening star.    [Washington] 1928-06-30   \n",
       "\n",
       "                                            raw_text  \n",
       "0  -s*\\nFriday, January 13, 1956\\ns\\nThe south Fl...  \n",
       "1  ' WILLIAM F. BRODT,!\\nHATMAKER, IS DEAD\\n, Fou...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "wjTfqq38e0XB"
   },
   "outputs": [],
   "source": [
    "# sort by date\n",
    "df = df.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "3XYFLmRhe7Gp"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>city</th>\n",
       "      <th>date</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>evening star.</td>\n",
       "      <td>[Washington]</td>\n",
       "      <td>1928-06-30</td>\n",
       "      <td>' WILLIAM F. BRODT,!\\nHATMAKER, IS DEAD\\n, Fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>southern jewish weekly.</td>\n",
       "      <td>[Jacksonville]</td>\n",
       "      <td>1956-01-13</td>\n",
       "      <td>-s*\\nFriday, January 13, 1956\\ns\\nThe south Fl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title            city       date  \\\n",
       "1            evening star.    [Washington] 1928-06-30   \n",
       "0  southern jewish weekly.  [Jacksonville] 1956-01-13   \n",
       "\n",
       "                                            raw_text  \n",
       "1  ' WILLIAM F. BRODT,!\\nHATMAKER, IS DEAD\\n, Fou...  \n",
       "0  -s*\\nFriday, January 13, 1956\\ns\\nThe south Fl...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epH12SFJfJm6"
   },
   "source": [
    "### Process text\n",
    "We can now porcess our text for analysis. The text provded by Chronicling America comes from optical character recognition (ocr) and the accuracy of ocr can be low. Here I will remove new line characters (`\\n`), stop words, and then lemamtize the text.\n",
    "\n",
    "**Rememeber** the decisions you make in how to process your text should be based on the kind of analysis you want to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "m6Urrlffe8ro"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting spacy<3.6.0,>=3.5.0 (from en-core-web-sm==3.5.0)\n",
      "  Downloading spacy-3.5.4-cp311-cp311-macosx_10_9_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.6)\n",
      "Collecting thinc<8.2.0,>=8.1.8 (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0)\n",
      "  Downloading thinc-8.1.12-cp311-cp311-macosx_10_9_x86_64.whl (858 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m858.7/858.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.31.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0)\n",
      "  Downloading pydantic-1.10.13-cp311-cp311-macosx_10_9_x86_64.whl (2.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alyssawilliams/miniconda3/lib/python3.11/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.3)\n",
      "Installing collected packages: pydantic, thinc, spacy, en-core-web-sm\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.5.2\n",
      "    Uninstalling pydantic-2.5.2:\n",
      "      Successfully uninstalled pydantic-2.5.2\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.2.1\n",
      "    Uninstalling thinc-8.2.1:\n",
      "      Successfully uninstalled thinc-8.2.1\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.7.2\n",
      "    Uninstalling spacy-3.7.2:\n",
      "      Successfully uninstalled spacy-3.7.2\n",
      "Successfully installed en-core-web-sm-3.5.0 pydantic-1.10.13 spacy-3.5.4 thinc-8.1.12\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# write function to process text\n",
    "# load nlp model\n",
    "! python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.disable_pipes('ner', 'parser')  # these are unnecessary for the task at hand\n",
    "\n",
    "def process_text(text):\n",
    "    \"\"\"Remove new line characters and lemmatize text. Returns string of lemmas\"\"\"\n",
    "    text = text.replace('\\n', ' ')\n",
    "    doc = nlp(text)\n",
    "    tokens = [token for token in doc]\n",
    "    no_stops = [token for token in tokens if not token.is_stop]\n",
    "    no_punct = [token for token in no_stops if token.is_alpha]\n",
    "    lemmas = [token.lemma_ for token in no_punct]\n",
    "    lemmas_lower = [lemma.lower() for lemma in lemmas]\n",
    "    lemmas_string = ' '.join(lemmas_lower)\n",
    "    return lemmas_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "VkQk9wuXfrwM"
   },
   "outputs": [],
   "source": [
    "# apply process_text function\n",
    "# this may take a few minutes\n",
    "df['lemmas'] = df['raw_text'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "7UU3K6rkfsRM"
   },
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df.to_csv(f'../PythonExercises/{search_term}{start_date}-{end_date}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
